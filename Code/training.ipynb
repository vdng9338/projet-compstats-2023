{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric import datasets\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from losses import kl_div_vmf, reconstruction_loss\n",
    "from train_utils import get_edge_probs\n",
    "from models import VGAE\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = datasets.Planetoid(root='/__data/Cora', name='Cora', split='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False) # because we perform negative sampling at each epoch ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = transform(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488])\n",
      "val data Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[263], pos_edge_label_index=[2, 263], neg_edge_label=[263], neg_edge_label_index=[2, 263])\n",
      "test data Data(x=[2708, 1433], edge_index=[2, 9502], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[527], pos_edge_label_index=[2, 527], neg_edge_label=[527], neg_edge_label_index=[2, 527])\n",
      "10556\n",
      "10556\n"
     ]
    }
   ],
   "source": [
    "print('train data', train_data)\n",
    "print('val data', val_data)\n",
    "print('test data', test_data)\n",
    "\n",
    "print(dataset[0].edge_index.shape[1])\n",
    "print(train_data.pos_edge_label.size(0)*2 + val_data.pos_edge_label.size(0) + val_data.neg_edge_label.size(0) + test_data.pos_edge_label.size(0) + test_data.neg_edge_label.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['neg_edge_label_index'] = negative_sampling(train_data.pos_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim 1433\n"
     ]
    }
   ],
   "source": [
    "feature_dim = dataset[0].x.shape[1]\n",
    "print('input dim', feature_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 526])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_edge_label_index = torch.cat([val_data.pos_edge_label_index, val_data.neg_edge_label_index], dim=1)\n",
    "val_edge_label_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out torch.Size([2708, 2708])\n",
      "mus torch.Size([2708, 16])\n",
      "logsigmas2s torch.Size([2708, 16])\n",
      "edge probs True\n"
     ]
    }
   ],
   "source": [
    "n_vgae = VGAE(input_dim=feature_dim, latent_dim=16, dropout=0.0, latent_distr='normal').to(device)\n",
    "\n",
    "out_n_vgae, mus_n_vgae, logsigmas2s_n_vgae  = n_vgae(val_data.x.to(device), val_edge_label_index.to(device))\n",
    "print('out', out_n_vgae.shape)\n",
    "print('mus', mus_n_vgae.shape)\n",
    "print('logsigmas2s', logsigmas2s_n_vgae.shape)\n",
    "labs, edge_probs = get_edge_probs(out_n_vgae, val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "print('edge probs', len(edge_probs)==len(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out torch.Size([2708, 2708])\n",
      "mus torch.Size([2708, 16])\n",
      "logkappas torch.Size([2708])\n",
      "ws torch.Size([2708])\n",
      "epss torch.Size([2708])\n",
      "bs torch.Size([2708])\n",
      "edge probs True\n"
     ]
    }
   ],
   "source": [
    "s_vgae = VGAE(input_dim=feature_dim, latent_dim=16, dropout=0.0, latent_distr='vMF').to(device)\n",
    "\n",
    "\n",
    "out_s_vgae, mus_s_vgae, logkappas_s_vgae, ws, epss, bs = s_vgae(val_data.x.to(device), val_edge_label_index.to(device))\n",
    "print('out', out_s_vgae.shape)\n",
    "print('mus', mus_s_vgae.shape)\n",
    "print('logkappas', logkappas_s_vgae.shape)\n",
    "print('ws', ws.shape)\n",
    "print('epss', epss.shape)\n",
    "print('bs', bs.shape)\n",
    "labs, edge_probs = get_edge_probs(out_s_vgae, val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "print('edge probs', len(edge_probs)==len(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(s_vgae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train $\\mathcal{S}$-VGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_recon tensor(7146.7388, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-5276.0596, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:   0, VAL AUC: 0.5238\n",
      "Epoch   0, TRAIN LOSS: 1870.6792\n",
      "loss_recon tensor(7261.5425, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-22165.7461, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(7048.7354, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-38206.8281, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(7198.1113, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-51921.5352, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(7095.3247, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-63185.2188, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(7191.2954, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-75338.8828, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(7168.1729, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-84302.8750, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(7172.1758, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-91650.3359, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(7100.4448, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-97954.0312, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6839.6289, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-102039.1094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6881.9980, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-107828.7344, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  10, VAL AUC: 0.5207\n",
      "Epoch  10, TRAIN LOSS: -100946.7344\n",
      "loss_recon tensor(6681.0962, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110870.8203, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6561.0850, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112157.0781, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6693.8145, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114025.0781, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6618.1709, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-117444.1484, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6630.3965, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-117540.4453, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6545.9956, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118559.2422, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6654.8306, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-120294.7500, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6570.9678, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-120517.7344, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6549.9219, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-120610.1094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6578.4980, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-120936.5000, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  20, VAL AUC: 0.5249\n",
      "Epoch  20, TRAIN LOSS: -114358.0000\n",
      "loss_recon tensor(6566.8271, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-122846.1094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6595.8340, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-121388.8047, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6532.0117, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-120438.5312, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6577.9771, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-121981.4219, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6516.0371, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-119673.9531, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6564.3193, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-119380.5938, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6513.7012, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-119584.6484, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6574.9111, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-119846.0625, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6587.9883, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118473.1953, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6511.0234, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-117244.7656, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  30, VAL AUC: 0.5042\n",
      "Epoch  30, TRAIN LOSS: -110733.7422\n",
      "loss_recon tensor(6501.0088, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-117040.2734, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6541.1445, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118917.5000, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6596.0137, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-119377.3906, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6463.4688, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116850.5625, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6520.5439, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118666.9375, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6558.9766, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116981.0703, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6493.7188, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118628.0781, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6582.1777, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116997.5859, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6542.0469, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-119206.5781, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6489.7266, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118387.0938, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  40, VAL AUC: 0.5230\n",
      "Epoch  40, TRAIN LOSS: -111897.3672\n",
      "loss_recon tensor(6528.1323, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118792.5391, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6483.6484, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-119088.6797, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6486.9487, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118313.7188, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6498.0703, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116171.9219, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6536.2163, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-118793.8203, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6539.2178, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116706.6094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6487.4478, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116635.7500, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6551.6807, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115192.3828, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6527.9668, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115572.1719, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6521.7749, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116215.9453, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  50, VAL AUC: 0.5396\n",
      "Epoch  50, TRAIN LOSS: -109694.1719\n",
      "loss_recon tensor(6557.8838, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-117249.4609, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6472.3491, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116626.9531, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6524.5771, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115153.5625, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6542.9692, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115654.9141, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6504.4404, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116596.6641, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6516.5464, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114551.1797, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6517.4932, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115365.0312, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6499.6875, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114730.9922, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6451.4170, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115221.8594, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6493.6826, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115434.6484, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  60, VAL AUC: 0.4887\n",
      "Epoch  60, TRAIN LOSS: -108940.9688\n",
      "loss_recon tensor(6519.3042, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114488.7500, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6521.2183, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114854.5078, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6467.3936, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116224.8906, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6478.7773, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114628.1797, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6532.7720, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114008.1562, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6467.3193, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114094.6016, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6569.5264, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114625.7578, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6502.5195, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113197.9141, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6468.2510, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113207.8438, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6521.7822, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112971.4141, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  70, VAL AUC: 0.4244\n",
      "Epoch  70, TRAIN LOSS: -106449.6328\n",
      "loss_recon tensor(6489.5088, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112889.1953, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6474.4023, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113704.7578, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6453.5562, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113520.3672, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6495.8838, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114482.6328, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6454.4917, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113838.1094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6489.9072, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112189., grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6470.4355, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114772.8203, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6490.4033, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115658.3750, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6496.3320, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113926.3359, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6497.9805, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113021.2734, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  80, VAL AUC: 0.4884\n",
      "Epoch  80, TRAIN LOSS: -106523.2969\n",
      "loss_recon tensor(6454.0571, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113949.2031, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6481.3022, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112237.6094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6464.1948, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114756.2500, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6486.9341, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114497.9766, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6487.6152, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114307.7891, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6438.4785, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113902.0391, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6439.6353, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114456.3906, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6474.4951, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114235.4297, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6473.8228, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115471.1406, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6454.6909, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114883.3359, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch:  90, VAL AUC: 0.4972\n",
      "Epoch  90, TRAIN LOSS: -108428.6484\n",
      "loss_recon tensor(6448.8091, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114113.7969, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6480.6504, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113717.8203, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6499.4512, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113916.6328, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6479.9746, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115704.7344, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6491.1499, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114718.1016, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6426.2285, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113292.5391, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6435.2085, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115262.4141, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6526.8828, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114838.3906, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6552.3345, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113259.6328, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6493.5664, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115484.4609, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 100, VAL AUC: 0.4963\n",
      "Epoch 100, TRAIN LOSS: -108990.8906\n",
      "loss_recon tensor(6496.9570, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114334.0938, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6464.7437, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114593.2578, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6465.7695, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115263.8828, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6442.2153, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114156.4531, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6467.4492, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114241.6719, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6451.3477, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112810.8125, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6444.2500, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115239.3594, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6505.1147, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113838.3906, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6474.2031, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112717.0156, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6456.2949, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114535.7500, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 110, VAL AUC: 0.4359\n",
      "Epoch 110, TRAIN LOSS: -108079.4531\n",
      "loss_recon tensor(6464.8916, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113572.4922, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6460.1431, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112825.5078, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6436.1929, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114854.0938, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6515.1963, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113879.3594, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6452.0771, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114197.9922, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6460.4717, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113574.6172, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6509.6816, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113813.8906, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6416.6982, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113308.2812, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6439.7822, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114864.6406, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6482.4258, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114672.0625, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 120, VAL AUC: 0.4862\n",
      "Epoch 120, TRAIN LOSS: -108189.6406\n",
      "loss_recon tensor(6467.4189, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112237.2266, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6465.4780, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114265.2734, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6446.5908, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113513.4062, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6463.1592, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113284.7422, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6490.0537, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115323.8438, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6432.8232, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113424.6094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6421.9839, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114201.7188, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6475.1968, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115711.9141, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6519.9619, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-116372.9766, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6457.9141, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-117578.4141, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 130, VAL AUC: 0.4843\n",
      "Epoch 130, TRAIN LOSS: -111120.5000\n",
      "loss_recon tensor(6459.1719, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113881.4766, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6422.3501, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113628.4922, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6503.4102, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114758.3516, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6460.7988, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113087.2578, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6473.9087, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114278.6562, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6466.3154, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113408.8125, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6448.6919, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112762.9453, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6517.2559, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113646.4375, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6395.0752, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112962.4062, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6459.3618, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111830.9609, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 140, VAL AUC: 0.4822\n",
      "Epoch 140, TRAIN LOSS: -105371.6016\n",
      "loss_recon tensor(6519.0229, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112293.2188, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6472.9980, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112823.5547, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6503.0518, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-115259.2109, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6469.8896, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-114261.3906, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6443.5830, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112035.1328, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6449.4648, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113408.6094, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6464.8022, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110251.6953, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6512.6689, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112777.4375, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6478.7495, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112724.0781, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6428.9927, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110490.8281, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 150, VAL AUC: 0.5039\n",
      "Epoch 150, TRAIN LOSS: -104061.8359\n",
      "loss_recon tensor(6466.7246, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112107.9609, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6436.5107, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112813.5859, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6469.3901, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112434.2344, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6446.7920, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111345.1562, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6429.8271, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111142.6875, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6428.6123, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112250.4219, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6461.8076, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111855.3438, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6470.5557, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111733.4922, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6444.3027, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112196.3672, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6423.8291, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112084.0547, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 160, VAL AUC: 0.5067\n",
      "Epoch 160, TRAIN LOSS: -105660.2266\n",
      "loss_recon tensor(6442.6699, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112929.0781, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6481.6611, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111526., grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6401.1768, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110793.8672, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6422.7744, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110812.9609, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6475.8916, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112059.9141, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6455.2563, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111749.4297, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6447.8809, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111386.2891, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6417.8872, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110830.2031, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6481.8926, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-109845.1250, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6441.7441, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111168.0391, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 170, VAL AUC: 0.4604\n",
      "Epoch 170, TRAIN LOSS: -104726.2969\n",
      "loss_recon tensor(6428.6533, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112176.6562, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6452.6660, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110656.8281, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6432.4907, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112089.7891, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6453.5874, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111929.1953, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6448.6455, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111344.0625, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6410.8765, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112664.9062, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6457.8916, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112953.1484, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6444.6553, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-113171.4922, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6456.1777, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111967.6953, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6424.8247, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110051.4453, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 180, VAL AUC: 0.5181\n",
      "Epoch 180, TRAIN LOSS: -103626.6172\n",
      "loss_recon tensor(6454.2373, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110185.9531, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6435.7974, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111730.6875, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6451.7949, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110967.7031, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6451.4160, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112027.7344, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6434.3525, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110557.6250, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6429.1362, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111366.9453, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6443.6025, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111254.0469, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6435.4570, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-109612.7188, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6437.3955, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111310.3672, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6446.3350, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112672.8438, grad_fn=<kl_div_vmfBackward>)\n",
      "Epoch: 190, VAL AUC: 0.5184\n",
      "Epoch 190, TRAIN LOSS: -106226.5078\n",
      "loss_recon tensor(6428.7715, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110604.7500, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6428.5493, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111345.2109, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6405.2417, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-112245.8359, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6403.7046, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111801.4844, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6416.9731, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111683.4688, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6451.1904, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110063.6250, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6450.3154, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-110152.5391, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6440.2393, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111635.8438, grad_fn=<kl_div_vmfBackward>)\n",
      "loss_recon tensor(6461.8691, grad_fn=<NegBackward0>)\n",
      "kl_loss tensor(-111696.7344, grad_fn=<kl_div_vmfBackward>)\n"
     ]
    }
   ],
   "source": [
    "log_loss = {'train': [] }\n",
    "log_metrics = {'val_auc' : [],\n",
    "               'val_ap' : []}\n",
    "val_edge_label_index = torch.cat([val_data.pos_edge_label_index, val_data.neg_edge_label_index], dim=1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # negative sampling \n",
    "    train_neg_edge_index = negative_sampling(train_data.pos_edge_label_index)\n",
    "    train_data['edge_label_index'] = torch.cat([train_data.pos_edge_label_index, train_neg_edge_index], dim=1)\n",
    "\n",
    "\n",
    "    kl = kl_div_vmf.apply\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, mus, logkappas, ws, epss, bs = s_vgae(train_data.x.to(device), train_data.edge_label_index.to(device) )\n",
    "    kappas = torch.exp(logkappas)\n",
    "\n",
    "    print('kappa', kappas)\n",
    "    kl_loss = kl(kappas, mus) \n",
    "    loss_recon = reconstruction_loss(output, train_data.pos_edge_label_index, train_neg_edge_index)\n",
    "    loss = loss_recon + kl_loss\n",
    "    print('loss_recon', loss_recon)  \n",
    "    print('kl_loss', kl_loss)\n",
    "    # print('loss', loss)\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        log_loss['train'].append(loss.item())\n",
    "        if epoch % 5 == 0:\n",
    "            out_val, mus_val, logkappas_val, ws, epss, bs = s_vgae(val_data.x.to(device), val_edge_label_index.to(device))\n",
    "            val_labs, edge_probs_val = get_edge_probs(out_val, val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "            log_metrics['val_auc'].append(roc_auc_score(val_labs, edge_probs_val))\n",
    "            log_metrics['val_ap'].append(average_precision_score(val_labs, edge_probs_val))\n",
    "        \n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch: {:3d}, VAL AUC: {:.4f}'.format(epoch, log_metrics['val_auc'][-1]))\n",
    "            print(f'Epoch {epoch:3d}, TRAIN LOSS: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(log_loss):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(log_loss['train'], label='train')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.set_title('Learning curves')\n",
    "\n",
    "    plt.show()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves(log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('results/loss_train.pkl', 'wb') as f:\n",
    "    pickle.dump(log_loss, f)\n",
    "\n",
    "with open('results/log_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(log_metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search \n",
    "as done in the article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "latent_dim = [8, 16, 32]\n",
    "learning_rates = [.01, .005, .001]\n",
    "\n",
    "results = Path('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, lr in product(latent_dim, learning_rates):\n",
    "    metrics =  {\n",
    "        'train_loss' : [],\n",
    "        'val_auc' : [],\n",
    "        'val_ap' : []\n",
    "    }\n",
    "\n",
    "    val_edge_label_index = torch.cat([val_data.pos_edge_label_index, val_data.neg_edge_label_index], dim=1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # negative sampling \n",
    "        train_neg_edge_index = negative_sampling(train_data.pos_edge_label_index)\n",
    "        train_data['edge_label_index'] = torch.cat([train_data.pos_edge_label_index, train_neg_edge_index], dim=1)\n",
    "\n",
    "        kl = kl_div_vmf.apply\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, mus, logkappas, ws, epss, bs = s_vgae(train_data.x.to(device), train_data.edge_label_index.to(device) )\n",
    "        kappas = torch.exp(logkappas)\n",
    "        kl_loss = kl(kappas, mus) \n",
    "        loss_recon = reconstruction_loss(output, train_data.pos_edge_label_index, train_neg_edge_index)\n",
    "        loss = loss_recon + kl_loss\n",
    "        # print('loss_recon', loss_recon)  \n",
    "        # print('kl_loss', kl_loss)\n",
    "        # print('loss', loss)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            metrics['train_loss'].append(loss.item())\n",
    "\n",
    "            out_val, mus_val, logkappas_val, ws, epss, bs = s_vgae(val_data.x.to(device), val_edge_label_index.to(device))\n",
    "            val_labs, edge_probs_val = get_edge_probs(out_val, val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "            metrics['val_auc'].append(roc_auc_score(val_labs, edge_probs_val))\n",
    "            metrics['val_ap'].append(average_precision_score(val_labs, edge_probs_val))\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print('Epoch: {:3d}, VAL AUC: {:.4f}'.format(epoch, log_metrics['val_auc'][-1]))\n",
    "                print(f'Epoch {epoch:3d}, TRAIN LOSS: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "with open(results / f's_vgae_dim{d}_lr{lr}.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
